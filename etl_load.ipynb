{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea47e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required libraries.\n",
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "raw_df= pd.read_csv(r\"C:\\Users\\ADMIN\\Downloads\\Transformed\\transformed_full.csv\")\n",
    "incremental_df = pd.read_csv(r\"C:\\Users\\ADMIN\\Downloads\\Transformed\\transformed_incremental.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3494dbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes have been successfully saved as parquet files.\n",
      "Preview of transformed_full.parquet:\n",
      "   order_id customer_name  product  quantity  unit_price           order_date  \\\n",
      "0         4           Eve   Laptop       2.0       750.0  2024-07-01 00:00:00   \n",
      "1         7       Charlie  Monitor       2.0       750.0  2024-02-02 00:00:00   \n",
      "2        10           Eve  Monitor       1.0       500.0  2024-02-28 00:00:00   \n",
      "3        12       Charlie   Tablet       2.0       750.0  2024-03-26 00:00:00   \n",
      "4        13         Frank   Tablet       1.0       750.0  2024-04-28 00:00:00   \n",
      "\n",
      "   total_price  \n",
      "0       1500.0  \n",
      "1       1500.0  \n",
      "2        500.0  \n",
      "3       1500.0  \n",
      "4        750.0  \n",
      "\n",
      "Preview of transformed_incremental.parquet:\n",
      "   order_id customer_name product  quantity  unit_price           order_date  \\\n",
      "0       105         Heidi  Tablet       2.0       600.0  2024-05-21 00:00:00   \n",
      "1       109         Grace  Laptop       2.0       600.0  2024-05-29 00:00:00   \n",
      "\n",
      "   total_price  \n",
      "0       1200.0  \n",
      "1       1200.0  \n"
     ]
    }
   ],
   "source": [
    "# use pandas.to_parquet() to save the dataframes as parquet files\n",
    "raw_df.to_parquet(r\"C:\\Users\\ADMIN\\Downloads\\Loaded\\transformed_full.parquet\", index=False)\n",
    "incremental_df.to_parquet(r\"C:\\Users\\ADMIN\\Downloads\\Loaded\\transformed_incremental.parquet\", index=False)\n",
    "# print a message to confirm that the files have been saved\n",
    "print(\"Dataframes have been successfully saved as parquet files.\")\n",
    "\n",
    "# preview the stored parquet files\n",
    "raw_df_preview = pd.read_parquet(r\"C:\\Users\\ADMIN\\Downloads\\Loaded\\transformed_full.parquet\")\n",
    "incremental_df_preview = pd.read_parquet(r\"C:\\Users\\ADMIN\\Downloads\\Loaded\\transformed_incremental.parquet\")\n",
    "\n",
    "# print the first few rows of the previewed dataframes\n",
    "print(\"Preview of transformed_full.parquet:\")  \n",
    "print(raw_df_preview.head())\n",
    "print(\"\\nPreview of transformed_incremental.parquet:\")      \n",
    "print(incremental_df_preview.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
